import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
import itertools
from sklearn.linear_model import LinearRegression

data=load_iris()

print(data.target)

print(data.data)

print(data.target_names)

print(data.feature_names)

iris_df=pd.DataFrame(data=data.data, columns=data.feature_names)
target_df=pd.DataFrame(data=data.target, columns=['species'])
iris_df.head()

def converter(s):
    if s==0:
        return 'setosa'
    elif s==1:
        return 'versicolor'
    else:
        return 'virginica'
target_df['species']=target_df['species'].apply(converter)
iris_df=pd.concat([iris_df,target_df],axis=1)

iris_df.head()

print(target_df.head())

X=iris_df['sepal width (cm)'].values.reshape(-1,1)
y=iris_df['sepal length (cm)']

X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.33,random_state=101)

lr=LinearRegression()
lr.fit(X,y)

m=lr.coef_
c=lr.intercept_
print("y=",m,"x+",c)

pred=lr.predict(X_test)
print(X_test[:5])

print(pred[:5])

print(y_test[:5])

print("RMSE",metrics.mean_squared_error(y_test,pred,squared=False))
print("MSE",metrics.mean_squared_error(y_test,pred))
print("MAE",metrics.mean_absolute_error(y_test,pred))

plt.scatter(X_test,y_test,color="b")
plt.plot(X_test,pred,color="r")
plt.show()

def myfunc(p):
    return (-0.22*p)+6.53
print(myfunc(4))

